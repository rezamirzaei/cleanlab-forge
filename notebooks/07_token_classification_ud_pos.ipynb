{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 07 â€” Token Classification with Cleanlab\n",
    "\n",
    "Token-level POS tagging with Cleanlab label issue detection."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T18:53:15.369306Z",
     "start_time": "2026-02-08T18:53:15.313701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'src').exists(): sys.path.insert(0, str(cwd / 'src'))\n",
    "elif (cwd.parent / 'src').exists(): sys.path.insert(0, str(cwd.parent / 'src'))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T18:53:16.879862Z",
     "start_time": "2026-02-08T18:53:15.381918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from cleanlab_demo.tasks import TokenClassificationTask, TokenClassificationConfig\n",
    "from cleanlab_demo.data.providers import UDEnglishEWTProvider"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T18:55:39.569664Z",
     "start_time": "2026-02-08T18:53:16.925798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = TokenClassificationTask(UDEnglishEWTProvider())\n",
    "config = TokenClassificationConfig(max_train_sentences=1000, max_dev_sentences=300, noise_frac=0.0, cv_folds=3, prune_frac=0.03, seed=42)\n",
    "result = task.run(config)\n",
    "result"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezami/PycharmProjects/Cleanlab_demo/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TokenClassificationResult(timestamp='2026-02-08T18:55:39.522019+00:00', task='token_classification', dataset='UD_English-EWT (UPOS)', data_dir=None, n_train_sentences=1000, n_dev_sentences=300, n_classes=17, noise=TokenClassificationNoiseSummary(fraction_tokens=0.0, n_corrupted_tokens=0), cleanlab=TokenClassificationCleanlabSummary(cv_folds=3, n_token_issues_found=509, n_pruned_tokens=509, precision_at_prune=0.0, recall_at_prune=0.0), metrics=TokenClassificationMetricsByVariant(baseline=TokenClassificationMetrics(token_accuracy=0.907323055360897, macro_f1=0.8133885739705393), pruned_retrain=TokenClassificationMetrics(token_accuracy=0.9060967063770147, macro_f1=0.8133872420062793)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T18:55:39.670168Z",
     "start_time": "2026-02-08T18:55:39.584270Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(result.metrics.model_dump()).T",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                token_accuracy  macro_f1\n",
       "baseline              0.907323  0.813389\n",
       "pruned_retrain        0.906097  0.813387"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.907323</td>\n",
       "      <td>0.813389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruned_retrain</th>\n",
       "      <td>0.906097</td>\n",
       "      <td>0.813387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T18:55:39.880567Z",
     "start_time": "2026-02-08T18:55:39.749138Z"
    }
   },
   "cell_type": "code",
   "source": "result.cleanlab.model_dump()\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_folds': 3,\n",
       " 'n_token_issues_found': 509,\n",
       " 'n_pruned_tokens': 509,\n",
       " 'precision_at_prune': 0.0,\n",
       " 'recall_at_prune': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
